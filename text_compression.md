
## Text Compression
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/microsoft/LLMLingua.svg?style=social&label=Star)](https://github.com/microsoft/LLMLingua)[![Publish](https://img.shields.io/badge/Conference-EMNLP'23-blue)]()<br>[LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models](https://arxiv.org/abs/2310.05736) <br> Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu |<img width="1002" alt="image" src="https://github.com/microsoft/LLMLingua/blob/main/images/LLMLingua_framework.png"> |[Github](https://github.com/microsoft/LLMLingua) <br> [Paper](https://arxiv.org/abs/2310.05736)|
|[![Star](https://img.shields.io/github/stars/microsoft/LLMLingua.svg?style=social&label=Star)](https://github.com/microsoft/LLMLingua)<br> [LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression](https://arxiv.org/abs/2310.06839) <br> Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu |<img width="1002" alt="image" src="figures/longllmlingua.png"> |[Github](https://github.com/microsoft/LLMLingua) <br> [Paper](https://arxiv.org/abs/2310.06839)| 
|[![Publish](https://img.shields.io/badge/Conference-ICML'23%20Workshop-blue)]()<br>[EntropyRank: Unsupervised Keyphrase Extraction via Side-Information Optimization for Language Model-based Text Compression](https://arxiv.org/abs/2308.13399) <br> Alexander Tsvetkov. Alon Kipnis |<img width="1002" alt="image" src="figures/EntropyRank.png"> |[Paper](https://arxiv.org/abs/2308.13399)|
|[LLMZip: Lossless Text Compression using Large Language Models](https://arxiv.org/abs/2306.04050) <br> Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Dileep Kalathil, Jean-Francois Chamberland, Srinivas Shakkottai |<img width="1002" alt="image" src="figures/LLMZip.png"> |[Paper](https://arxiv.org/abs/2306.04050) \| [Unofficial Github](https://github.com/erika-n/GPTzip)|
|[![Star](https://img.shields.io/github/stars/princeton-nlp/AutoCompressors.svg?style=social&label=Star)](https://github.com/princeton-nlp/AutoCompressors)<br>[Adapting Language Models to Compress Contexts](https://arxiv.org/abs/2305.14788) <br> Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen |<img width="202" alt="image" src="figures/AutoCompressor.png"> |[Github](https://github.com/princeton-nlp/AutoCompressors) <br> [Paper](https://arxiv.org/abs/2305.14788)|
|[In-context Autoencoder for Context Compression in a Large Language Model](https://arxiv.org/abs/2307.06945) <br> Tao Ge, Jing Hu, Xun Wang, Si-Qing Chen, Furu Wei |<img width="502" alt="image" src="figures/ICAE.png"> |[Paper](https://arxiv.org/abs/2307.06945)|
|[Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Model](https://arxiv.org/abs/2310.02409) <br> Guanghui Qin, Corby Rosset, Ethan C. Chau, Nikhil Rao, Benjamin Van Durme |<img width="1002" alt="image" src="figures/nugget2D.png"> |[Paper](https://arxiv.org/abs/2310.02409)|
|[Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning](https://arxiv.org/abs/2312.08901) <br> Xijie Huang, Li Lyna Zhang, Kwang-Ting Cheng, Mao Yang |<img width="1002" alt="image" src="figures/CoT-Max.png"> |[Paper](https://arxiv.org/abs/2312.08901)|
|[ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding](https://arxiv.org/abs/2402.13485) <br> Shuzhang Zhong, Zebin Yang, Meng Li, Ruihao Gong, Runsheng Wang, Ru Huang |<img width="1002" alt="image" src="figures/ProPD.png"> |[Paper](https://arxiv.org/abs/2402.13485)|
|[Learning to Compress Prompt in Natural Language Formats](https://arxiv.org/abs/2402.18700) <br> Yu-Neng Chuang, Tianwei Xing, Chia-Yuan Chang, Zirui Liu, Xun Chen, Xia Hu |<img width="1002" alt="image" src="https://arxiv.org/html/2402.18700v1/x1.png"> |[Paper](https://arxiv.org/abs/2402.18700)|
|[LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/abs/2403.12968) <br> Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin et al |<img width="1002" alt="image" src="https://arxiv.org/html/2403.12968v1/x1.png"> |[Paper](https://arxiv.org/abs/2403.12968)|
|[![Star](https://img.shields.io/github/stars/3DAgentWorld/Toolkit-for-Prompt-Compression.svg?style=social&label=Star)](https://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression)<br>[PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models](https://arxiv.org/abs/2403.17411) <br> Jinyi Li, Yihuai Lan, Lei Wang, Hao Wang |<img width="1002" alt="image" src="https://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression/raw/main/imgs/architecture.png"> |[Github](https://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression) <br> [Paper](https://arxiv.org/abs/2403.17411)|
|[PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt Compression](https://arxiv.org/abs/2404.00489) <br> Muhammad Asif Ali, Zhengping Li, Shu Yang, Keyuan Cheng, Yang Cao, Tianhao Huang, Lijie Hu, Lu Yu, Di Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2404.00489v1/x2.png"> |[Paper](https://arxiv.org/abs/2404.00489)|
|[Training LLMs over Neurally Compressed Text](https://arxiv.org/abs/2404.03626) <br> Brian Lester, Jaehoon Lee, Alex Alemi, Jeffrey Pennington, Adam Roberts, Jascha Sohl-Dickstein, Noah Constant |<img width="302" alt="image" src="https://arxiv.org/html/2404.03626v1/x1.png"> |[Paper](https://arxiv.org/abs/2404.03626)|
|[![Publish](https://img.shields.io/badge/Conference-IPCA'24-blue)]()<br>[Adapting LLMs for Efficient Context Processing through Soft Prompt Compression](https://arxiv.org/abs/2404.04997) <br> Cangqing Wang, Yutian Yang, Ruisi Li, Dan Sun, Ruicong Cai, Yuzhu Zhang, Chengqian Fu, Lillian Floyd |<img width="1002" alt="image" src="https://arxiv.org/html/2404.04997v1/extracted/5508155/Fig2.png"> |[Paper](https://arxiv.org/abs/2404.04997)|
|[![Star](https://img.shields.io/github/stars/acr-memorization/.svg?style=social&label=Star)](https://github.com/acr-memorization/)<br>[Rethinking LLM Memorization through the Lens of Adversarial Compression](https://arxiv.org/abs/2404.15146) <br> Avi Schwarzschild, Zhili Feng, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter |<img width="1002" alt="image" src="https://pratyushmaini-acr-viewer.hf.space/file=/tmp/gradio/f054d27283291fa78df9949f26ac605dbea31398/ACR.png"> |[Github](https://github.com/locuslab/acr-memorization/) <br> [Paper](https://arxiv.org/abs/2404.15146) <br> [Project](https://locuslab.github.io/acr-memorization/)|
|[Brevity is the soul of wit: Pruning long files for code generation](https://arxiv.org/abs/2407.00434) <br> Aaditya K. Singh, Yu Yang, Kushal Tirumala, Mostafa Elhoushi, Ari S. Morcos |<img width="1002" alt="image" src="https://arxiv.org/html/2407.00434v1/x1.png"> |[Paper](https://arxiv.org/abs/2407.00434)|[//]: #07/03
|[PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning](https://arxiv.org/abs/2407.02211) <br> Jiaru Zou, Mengyu Zhou, Tao Li, Shi Han, Dongmei Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2407.02211v1/x2.png"> |[Paper](https://arxiv.org/abs/2407.02211)|[//]: #07/05
|[Entropy Law: The Story Behind Data Compression and LLM Performance](https://arxiv.org/abs/2407.06645) <br> Mingjia Yin, Chuhan Wu, Yufei Wang, Hao Wang, Wei Guo, Yasheng Wang, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2407.06645v1/x1.png"> |[Paper](https://arxiv.org/abs/2407.06645)|[//]: #07/10
|[![Publish](https://img.shields.io/badge/Conference-ICML'24%20EsFoMo-blue)]()<br>[Characterizing Prompt Compression Methods for Long Context Inference](https://arxiv.org/abs/2407.08892) <br> Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Kurt Keutzer, Amir Gholami |<img width="1002" alt="image" src="https://arxiv.org/html/2407.08892v1/x3.png"> |[Paper](https://arxiv.org/abs/2407.08892)|[//]: #07/16
|[![Star](https://img.shields.io/github/stars/Wenshansilvia/attention_compressor.svg?style=social&label=Star)](https://github.com/Wenshansilvia/attention_compressor)<br>[QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression](https://arxiv.org/abs/2408.00274) <br> Wenshan Wang, Yihang Wang, Yixing Fan, Huaming Liao, Jiafeng Guo |<img width="1002" alt="image" src="https://github.com/Wenshansilvia/attention_compressor/blob/main/assets/method.png"> |[Github](https://github.com/Wenshansilvia/attention_compressor) <br> [Paper](https://arxiv.org/abs/2408.00274)|[//]: #08/08
|[![Star](https://img.shields.io/github/stars/ZongqianLi/500xCompressor.svg?style=social&label=Star)](https://github.com/ZongqianLi/500xCompressor)<br>[500xCompressor: Generalized Prompt Compression for Large Language Models](https://arxiv.org/abs/2408.03094) <br> Zongqian Li, Yixuan Su, Nigel Collier |<img width="1002" alt="image" src="https://arxiv.org/html/2408.03094v1/extracted/5776907/Figures/0-1.png"> |[Github](https://github.com/ZongqianLi/500xCompressor) <br> [Paper](https://arxiv.org/abs/2408.03094)|[//]: #08/08
|[![Star](https://img.shields.io/github/stars/howard-hou/instruction-aware-contextual-compressor.svg?style=social&label=Star)](https://github.com/howard-hou/instruction-aware-contextual-compressor)<br>[Enhancing and Accelerating Large Language Models via Instruction-Aware Contextual Compression](https://arxiv.org/abs/2408.15491) <br> Haowen Hou, Fei Ma, Binwen Bai, Xinxin Zhu, Fei Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2408.15491v1/extracted/5817813/arch.png"> |[Github](https://github.com/howard-hou/instruction-aware-contextual-compressor) <br> [Paper](https://arxiv.org/abs/2408.15491)|[//]: #09/02
|[Efficient LLM Context Distillation](https://arxiv.org/abs/2409.01930) <br> Rajesh Upadhayayaya, Zachary Smith, Chritopher Kottmyer, Manish Raj Osti | |[Paper](https://arxiv.org/abs/2409.01930)|[//]: #09/06
|[TACO-RL: Task Aware Prompt Compression Optimization with Reinforcement Learning](https://arxiv.org/abs/2409.13035) <br> Shivam Shandilya, Menglin Xia, Supriyo Ghosh, Huiqiang Jiang, Jue Zhang, Qianhui Wu, Victor Rühle |<img width="1002" alt="image" src="https://arxiv.org/html/2409.13035v2/x1.png"> |[Paper](https://arxiv.org/abs/2409.13035)|[//]: #09/27
|[![Star](https://img.shields.io/github/stars/Swathi-Shree-Narashiman/AlphaZip.svg?style=social&label=Star)](https://github.com/Swathi-Shree-Narashiman/AlphaZip)<br>[AlphaZip: Neural Network-Enhanced Lossless Text Compression](https://arxiv.org/abs/2409.15046) <br> Swathi Shree Narashiman, Nitin Chandrachoodan |<img width="1002" alt="image" src="https://arxiv.org/html/2409.15046v1/extracted/5873563/images/architecture_bloack_diagram.png"> |[Github](https://github.com/Swathi-Shree-Narashiman/AlphaZip) <br> [Paper](https://arxiv.org/abs/2409.15046)|[//]: #09/27
|[![Star](https://img.shields.io/github/stars/LengendaryHippopotamus/PartPrompt.svg?style=social&label=Star)](https://github.com/LengendaryHippopotamus/PartPrompt)<br>[Parse Trees Guided LLM Prompt Compression](https://arxiv.org/abs/2409.15395) <br> Wenhao Mao, Chengbin Hou, Tianyu Zhang, Xinyu Lin, Ke Tang, Hairong Lv |<img width="1002" alt="image" src="https://arxiv.org/html/2409.15395v1/x1.png"> |[Github](https://github.com/LengendaryHippopotamus/PartPrompt) <br> [Paper](https://arxiv.org/abs/2409.15395)|[//]: #09/27
|[![Star](https://img.shields.io/github/stars/fazalmittu/FineZip.svg?style=social&label=Star)](https://github.com/fazalmittu/FineZip)<br>[FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression](https://arxiv.org/abs/2409.17141) <br> Fazal Mittu, Yihuan Bu, Akshat Gupta, Ashok Devireddy, Alp Eren Ozdarendeli, Anant Singh, Gopala Anumanchipalli |<img width="1002" alt="image" src="https://arxiv.org/html/2409.17141v1/extracted/5879840/finezip_diagram.png"> |[Github](https://github.com/fazalmittu/FineZip) <br> [Paper](https://arxiv.org/abs/2409.17141)|[//]: #09/27
|[Perception Compressor:A training-free prompt compression method in long context scenarios](https://arxiv.org/abs/2409.19272) <br> Jiwei Tang, Jin Xu, Tingwei Lu, Hai Lin, Yiming Zhao, Hai-Tao Zheng |<img width="1002" alt="image" src="https://arxiv.org/html/2409.19272v1/x1.png"> |[Paper](https://arxiv.org/abs/2409.19272)|[//]: #10/02
|[![Publish](https://img.shields.io/badge/Conference-EMNLP'24%20Findings-blue)]()<br>[From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression](https://arxiv.org/abs/2410.04139) <br> Eunseong Choi, Sunkyung Lee, Minjin Choi, June Park, Jongwuk Lee |<img width="1002" alt="image" src="https://arxiv.org/html/2410.04139v1/extracted/5902409/Figures/fig_R2C_framework_2col_v4.png"> |[Paper](https://arxiv.org/abs/2410.04139)|[//]: #10/14
|[![Publish](https://img.shields.io/badge/Conference-EMNLP'24%20Findings-blue)]()<br>[Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability](https://arxiv.org/abs/2410.11786) <br> Tsz Ting Chung, Leyang Cui, Lemao Liu, Xinting Huang, Shuming Shi, Dit-Yan Yeung |<img width="202" alt="image" src="https://arxiv.org/html/2410.11786v1/x1.png"> |[Paper](https://arxiv.org/abs/2410.11786)|[//]: #10/21
|[![Star](https://img.shields.io/github/stars/noelkelias/multitok.svg?style=social&label=Star)](https://github.com/noelkelias/multitok)<br>[MultiTok: Variable-Length Tokenization for Efficient LLMs Adapted from LZW Compression](https://arxiv.org/abs/2410.21548) <br> Noel Elias, Homa Esfahanizadeh, Kaan Kale, Sriram Vishwanath, Muriel Medard |<img width="1002" alt="image" src="https://arxiv.org/html/2410.21548v1/extracted/5960495/Figures/MultiTok.png"> |[Github](https://github.com/noelkelias/multitok) <br> [Paper](https://arxiv.org/abs/2410.21548)|[//]: #11/17
|[![Star](https://img.shields.io/github/stars/kaistai/GenPI.svg?style=social&label=Star)](https://github.com/kaistai/GenPI)<br>[Generative Prompt Internalization](https://arxiv.org/abs/2411.15927) <br> Haebin Shin, Lei Ji, Yeyun Gong, Sungdong Kim, Eunbi Choi, Minjoon Seo |<img width="1002" alt="image" src="figures/GCD.png"> |[Github](https://github.com/kaistai/GenPI) <br> [Paper](https://arxiv.org/abs/2411.15927)|[//]: #12/02
|[JPPO: Joint Power and Prompt Optimization for Accelerated Large Language Model Services](https://arxiv.org/abs/2411.18010) <br> Feiran You, Hongyang Du, Kaibin Huang, Abbas Jamalipour |<img width="1002" alt="image" src="https://arxiv.org/html/2411.18010v1/x1.png"> |[Paper](https://arxiv.org/abs/2411.18010)|[//]: #12/07
|[A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression](https://arxiv.org/abs/2412.17483) <br> Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou |<img width="1002" alt="image" src="https://arxiv.org/html/2412.17483v1/x1.png"> |[Paper](https://arxiv.org/abs/2412.17483)|[//]: #12/30
|[![Star](https://img.shields.io/github/stars/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression.svg?style=social&label=Star)](https://github.com/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression)<br>[L3TC: Leveraging RWKV for Learned Lossless Low-Complexity Text Compression](https://arxiv.org/abs/2412.16642) <br> Junxuan Zhang, Zhengxue Cheng, Yan Zhao, Shihao Wang, Dajiang Zhou, Guo Lu, Li Song |<img width="1002" alt="image" src="https://arxiv.org/html/2412.16642v2/x2.png"> |[Github](https://github.com/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression) <br> [Paper](https://arxiv.org/abs/2412.16642)|[//]: #12/30
|[![Star](https://img.shields.io/github/stars/NL2G/promptoptme.svg?style=social&label=Star)](https://github.com/NL2G/promptoptme)<br>[PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics](https://arxiv.org/abs/2412.16120) <br> Daniil Larionov, Steffen Eger |<img width="1002" alt="image" src="https://arxiv.org/html/2412.16120v1/x1.png"> |[Github](https://github.com/NL2G/promptoptme) <br> [Paper](https://arxiv.org/abs/2412.16120)|[//]: #12/30
| [![Star](https://img.shields.io/github/stars/Workday/cpc.svg?style=social&label=Star)](https://github.com/Workday/cpc)![Publish](https://img.shields.io/badge/Conference-AAAI'25-blue)<br>[Prompt Compression with Context-Aware Sentence Encoding for Fast and Improved LLM Inference](https://arxiv.org/abs/2409.01227) <br> Barys Liskavets, Maxim Ushakov, Shuvendu Roy, Mark Klibanov, Ali Etemad, Shane Luke |<img width="1002" alt="image" src="https://arxiv.org/html/2409.01227v3/x1.png"> |[Github](https://github.com/Workday/cpc) <br> [Paper](https://arxiv.org/abs/2409.01227)|[//]: #12/30
| [Task-agnostic Prompt Compression with Context-aware Sentence Embedding and Reward-guided Task Descriptor](https://arxiv.org/abs/2502.13374v1) <br> Barys Liskavets, Shuvendu Roy, Maxim Ushakov, Mark Klibanov, Ali Etemad, Shane Luke |<img width="1002" alt="image" src="https://arxiv.org/html/2502.13374v1/x2.png"> | [Paper](https://arxiv.org/abs/2502.13374v1)|[//]: #12/30